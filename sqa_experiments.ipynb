{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sqa_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZbLp8eoQSF8z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKB8YaRk05Sl",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/tapas/blob/master/notebooks/sqa_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-07bRHwv0C7L",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 Priyal Narang\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSpOxRRH0BCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2020 Priyal Narang.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EACclxE7sP",
        "colab_type": "text"
      },
      "source": [
        "Running a Tapas fine-tuned checkpoint\n",
        "---\n",
        "This notebook shows how to load and make predictions with TAPAS model, which was introduced in the paper: [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-m_JoVCFCV0",
        "colab_type": "text"
      },
      "source": [
        "# Clone and install the repository\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF84Z-KayR3Z",
        "colab_type": "text"
      },
      "source": [
        "First, let's fetch the code from the github repository and install it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI6zyIM20Kw4",
        "colab_type": "code",
        "outputId": "6f29b119-ec0c-4605-abfe-48cfae270bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/google-research/tapas.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tapas'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/109)\u001b[K\rremote: Counting objects:   1% (2/109)\u001b[K\rremote: Counting objects:   2% (3/109)\u001b[K\rremote: Counting objects:   3% (4/109)\u001b[K\rremote: Counting objects:   4% (5/109)\u001b[K\rremote: Counting objects:   5% (6/109)\u001b[K\rremote: Counting objects:   6% (7/109)\u001b[K\rremote: Counting objects:   7% (8/109)\u001b[K\rremote: Counting objects:   8% (9/109)\u001b[K\rremote: Counting objects:   9% (10/109)\u001b[K\rremote: Counting objects:  10% (11/109)\u001b[K\rremote: Counting objects:  11% (12/109)\u001b[K\rremote: Counting objects:  12% (14/109)\u001b[K\rremote: Counting objects:  13% (15/109)\u001b[K\rremote: Counting objects:  14% (16/109)\u001b[K\rremote: Counting objects:  15% (17/109)\u001b[K\rremote: Counting objects:  16% (18/109)\u001b[K\rremote: Counting objects:  17% (19/109)\u001b[K\rremote: Counting objects:  18% (20/109)\u001b[K\rremote: Counting objects:  19% (21/109)\u001b[K\rremote: Counting objects:  20% (22/109)\u001b[K\rremote: Counting objects:  21% (23/109)\u001b[K\rremote: Counting objects:  22% (24/109)\u001b[K\rremote: Counting objects:  23% (26/109)\u001b[K\rremote: Counting objects:  24% (27/109)\u001b[K\rremote: Counting objects:  25% (28/109)\u001b[K\rremote: Counting objects:  26% (29/109)\u001b[K\rremote: Counting objects:  27% (30/109)\u001b[K\rremote: Counting objects:  28% (31/109)\u001b[K\rremote: Counting objects:  29% (32/109)\u001b[K\rremote: Counting objects:  30% (33/109)\u001b[K\rremote: Counting objects:  31% (34/109)\u001b[K\rremote: Counting objects:  32% (35/109)\u001b[K\rremote: Counting objects:  33% (36/109)\u001b[K\rremote: Counting objects:  34% (38/109)\u001b[K\rremote: Counting objects:  35% (39/109)\u001b[K\rremote: Counting objects:  36% (40/109)\u001b[K\rremote: Counting objects:  37% (41/109)\u001b[K\rremote: Counting objects:  38% (42/109)\u001b[K\rremote: Counting objects:  39% (43/109)\u001b[K\rremote: Counting objects:  40% (44/109)\u001b[K\rremote: Counting objects:  41% (45/109)\u001b[K\rremote: Counting objects:  42% (46/109)\u001b[K\rremote: Counting objects:  43% (47/109)\u001b[K\rremote: Counting objects:  44% (48/109)\u001b[K\rremote: Counting objects:  45% (50/109)\u001b[K\rremote: Counting objects:  46% (51/109)\u001b[K\rremote: Counting objects:  47% (52/109)\u001b[K\rremote: Counting objects:  48% (53/109)\u001b[K\rremote: Counting objects:  49% (54/109)\u001b[K\rremote: Counting objects:  50% (55/109)\u001b[K\rremote: Counting objects:  51% (56/109)\u001b[K\rremote: Counting objects:  52% (57/109)\u001b[K\rremote: Counting objects:  53% (58/109)\u001b[K\rremote: Counting objects:  54% (59/109)\u001b[K\rremote: Counting objects:  55% (60/109)\u001b[K\rremote: Counting objects:  56% (62/109)\u001b[K\rremote: Counting objects:  57% (63/109)\u001b[K\rremote: Counting objects:  58% (64/109)\u001b[K\rremote: Counting objects:  59% (65/109)\u001b[K\rremote: Counting objects:  60% (66/109)\u001b[K\rremote: Counting objects:  61% (67/109)\u001b[K\rremote: Counting objects:  62% (68/109)\u001b[K\rremote: Counting objects:  63% (69/109)\u001b[K\rremote: Counting objects:  64% (70/109)\u001b[K\rremote: Counting objects:  65% (71/109)\u001b[K\rremote: Counting objects:  66% (72/109)\u001b[K\rremote: Counting objects:  67% (74/109)\u001b[K\rremote: Counting objects:  68% (75/109)\u001b[K\rremote: Counting objects:  69% (76/109)\u001b[K\rremote: Counting objects:  70% (77/109)\u001b[K\rremote: Counting objects:  71% (78/109)\u001b[K\rremote: Counting objects:  72% (79/109)\u001b[K\rremote: Counting objects:  73% (80/109)\u001b[K\rremote: Counting objects:  74% (81/109)\u001b[K\rremote: Counting objects:  75% (82/109)\u001b[K\rremote: Counting objects:  76% (83/109)\u001b[K\rremote: Counting objects:  77% (84/109)\u001b[K\rremote: Counting objects:  78% (86/109)\u001b[K\rremote: Counting objects:  79% (87/109)\u001b[K\rremote: Counting objects:  80% (88/109)\u001b[K\rremote: Counting objects:  81% (89/109)\u001b[K\rremote: Counting objects:  82% (90/109)\u001b[K\rremote: Counting objects:  83% (91/109)\u001b[K\rremote: Counting objects:  84% (92/109)\u001b[K\rremote: Counting objects:  85% (93/109)\u001b[K\rremote: Counting objects:  86% (94/109)\u001b[K\rremote: Counting objects:  87% (95/109)\u001b[K\rremote: Counting objects:  88% (96/109)\u001b[K\rremote: Counting objects:  89% (98/109)\u001b[K\rremote: Counting objects:  90% (99/109)\u001b[K\rremote: Counting objects:  91% (100/109)\u001b[K\rremote: Counting objects:  92% (101/109)\u001b[K\rremote: Counting objects:  93% (102/109)\u001b[K\rremote: Counting objects:  94% (103/109)\u001b[K\rremote: Counting objects:  95% (104/109)\u001b[K\rremote: Counting objects:  96% (105/109)\u001b[K\rremote: Counting objects:  97% (106/109)\u001b[K\rremote: Counting objects:  98% (107/109)\u001b[K\rremote: Counting objects:  99% (108/109)\u001b[K\rremote: Counting objects: 100% (109/109)\u001b[K\rremote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/84)\u001b[K\rremote: Compressing objects:   2% (2/84)\u001b[K\rremote: Compressing objects:   3% (3/84)\u001b[K\rremote: Compressing objects:   4% (4/84)\u001b[K\rremote: Compressing objects:   5% (5/84)\u001b[K\rremote: Compressing objects:   7% (6/84)\u001b[K\rremote: Compressing objects:   8% (7/84)\u001b[K\rremote: Compressing objects:   9% (8/84)\u001b[K\rremote: Compressing objects:  10% (9/84)\u001b[K\rremote: Compressing objects:  11% (10/84)\u001b[K\rremote: Compressing objects:  13% (11/84)\u001b[K\rremote: Compressing objects:  14% (12/84)\u001b[K\rremote: Compressing objects:  15% (13/84)\u001b[K\rremote: Compressing objects:  16% (14/84)\u001b[K\rremote: Compressing objects:  17% (15/84)\u001b[K\rremote: Compressing objects:  19% (16/84)\u001b[K\rremote: Compressing objects:  20% (17/84)\u001b[K\rremote: Compressing objects:  21% (18/84)\u001b[K\rremote: Compressing objects:  22% (19/84)\u001b[K\rremote: Compressing objects:  23% (20/84)\u001b[K\rremote: Compressing objects:  25% (21/84)\u001b[K\rremote: Compressing objects:  26% (22/84)\u001b[K\rremote: Compressing objects:  27% (23/84)\u001b[K\rremote: Compressing objects:  28% (24/84)\u001b[K\rremote: Compressing objects:  29% (25/84)\u001b[K\rremote: Compressing objects:  30% (26/84)\u001b[K\rremote: Compressing objects:  32% (27/84)\u001b[K\rremote: Compressing objects:  33% (28/84)\u001b[K\rremote: Compressing objects:  34% (29/84)\u001b[K\rremote: Compressing objects:  35% (30/84)\u001b[K\rremote: Compressing objects:  36% (31/84)\u001b[K\rremote: Compressing objects:  38% (32/84)\u001b[K\rremote: Compressing objects:  39% (33/84)\u001b[K\rremote: Compressing objects:  40% (34/84)\u001b[K\rremote: Compressing objects:  41% (35/84)\u001b[K\rremote: Compressing objects:  42% (36/84)\u001b[K\rremote: Compressing objects:  44% (37/84)\u001b[K\rremote: Compressing objects:  45% (38/84)\u001b[K\rremote: Compressing objects:  46% (39/84)\u001b[K\rremote: Compressing objects:  47% (40/84)\u001b[K\rremote: Compressing objects:  48% (41/84)\u001b[K\rremote: Compressing objects:  50% (42/84)\u001b[K\rremote: Compressing objects:  51% (43/84)\u001b[K\rremote: Compressing objects:  52% (44/84)\u001b[K\rremote: Compressing objects:  53% (45/84)\u001b[K\rremote: Compressing objects:  54% (46/84)\u001b[K\rremote: Compressing objects:  55% (47/84)\u001b[K\rremote: Compressing objects:  57% (48/84)\u001b[K\rremote: Compressing objects:  58% (49/84)\u001b[K\rremote: Compressing objects:  59% (50/84)\u001b[K\rremote: Compressing objects:  60% (51/84)\u001b[K\rremote: Compressing objects:  61% (52/84)\u001b[K\rremote: Compressing objects:  63% (53/84)\u001b[K\rremote: Compressing objects:  64% (54/84)\u001b[K\rremote: Compressing objects:  65% (55/84)\u001b[K\rremote: Compressing objects:  66% (56/84)\u001b[K\rremote: Compressing objects:  67% (57/84)\u001b[K\rremote: Compressing objects:  69% (58/84)\u001b[K\rremote: Compressing objects:  70% (59/84)\u001b[K\rremote: Compressing objects:  71% (60/84)\u001b[K\rremote: Compressing objects:  72% (61/84)\u001b[K\rremote: Compressing objects:  73% (62/84)\u001b[K\rremote: Compressing objects:  75% (63/84)\u001b[K\rremote: Compressing objects:  76% (64/84)\u001b[K\rremote: Compressing objects:  77% (65/84)\u001b[K\rremote: Compressing objects:  78% (66/84)\u001b[K\rremote: Compressing objects:  79% (67/84)\u001b[K\rremote: Compressing objects:  80% (68/84)\u001b[K\rremote: Compressing objects:  82% (69/84)\u001b[K\rremote: Compressing objects:  83% (70/84)\u001b[K\rremote: Compressing objects:  84% (71/84)\u001b[K\rremote: Compressing objects:  85% (72/84)\u001b[K\rremote: Compressing objects:  86% (73/84)\u001b[K\rremote: Compressing objects:  88% (74/84)\u001b[K\rremote: Compressing objects:  89% (75/84)\u001b[K\rremote: Compressing objects:  90% (76/84)\u001b[K\rremote: Compressing objects:  91% (77/84)\u001b[K\rremote: Compressing objects:  92% (78/84)\u001b[K\rremote: Compressing objects:  94% (79/84)\u001b[K\rremote: Compressing objects:  95% (80/84)\u001b[K\rremote: Compressing objects:  96% (81/84)\u001b[K\rremote: Compressing objects:  97% (82/84)\u001b[K\rremote: Compressing objects:  98% (83/84)\u001b[K\rremote: Compressing objects: 100% (84/84)\u001b[K\rremote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "Receiving objects:   0% (1/109)   \rReceiving objects:   1% (2/109)   \rReceiving objects:   2% (3/109)   \rReceiving objects:   3% (4/109)   \rReceiving objects:   4% (5/109)   \rReceiving objects:   5% (6/109)   \rReceiving objects:   6% (7/109)   \rReceiving objects:   7% (8/109)   \rReceiving objects:   8% (9/109)   \rReceiving objects:   9% (10/109)   \rReceiving objects:  10% (11/109)   \rReceiving objects:  11% (12/109)   \rReceiving objects:  12% (14/109)   \rReceiving objects:  13% (15/109)   \rReceiving objects:  14% (16/109)   \rReceiving objects:  15% (17/109)   \rReceiving objects:  16% (18/109)   \rReceiving objects:  17% (19/109)   \rReceiving objects:  18% (20/109)   \rReceiving objects:  19% (21/109)   \rReceiving objects:  20% (22/109)   \rReceiving objects:  21% (23/109)   \rReceiving objects:  22% (24/109)   \rReceiving objects:  23% (26/109)   \rReceiving objects:  24% (27/109)   \rReceiving objects:  25% (28/109)   \rReceiving objects:  26% (29/109)   \rReceiving objects:  27% (30/109)   \rReceiving objects:  28% (31/109)   \rReceiving objects:  29% (32/109)   \rReceiving objects:  30% (33/109)   \rReceiving objects:  31% (34/109)   \rReceiving objects:  32% (35/109)   \rReceiving objects:  33% (36/109)   \rReceiving objects:  34% (38/109)   \rReceiving objects:  35% (39/109)   \rReceiving objects:  36% (40/109)   \rReceiving objects:  37% (41/109)   \rReceiving objects:  38% (42/109)   \rReceiving objects:  39% (43/109)   \rReceiving objects:  40% (44/109)   \rReceiving objects:  41% (45/109)   \rReceiving objects:  42% (46/109)   \rReceiving objects:  43% (47/109)   \rReceiving objects:  44% (48/109)   \rReceiving objects:  45% (50/109)   \rReceiving objects:  46% (51/109)   \rReceiving objects:  47% (52/109)   \rReceiving objects:  48% (53/109)   \rReceiving objects:  49% (54/109)   \rReceiving objects:  50% (55/109)   \rReceiving objects:  51% (56/109)   \rReceiving objects:  52% (57/109)   \rReceiving objects:  53% (58/109)   \rReceiving objects:  54% (59/109)   \rReceiving objects:  55% (60/109)   \rReceiving objects:  56% (62/109)   \rReceiving objects:  57% (63/109)   \rReceiving objects:  58% (64/109)   \rReceiving objects:  59% (65/109)   \rReceiving objects:  60% (66/109)   \rReceiving objects:  61% (67/109)   \rremote: Total 109 (delta 25), reused 103 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects:  62% (68/109)   \rReceiving objects:  63% (69/109)   \rReceiving objects:  64% (70/109)   \rReceiving objects:  65% (71/109)   \rReceiving objects:  66% (72/109)   \rReceiving objects:  67% (74/109)   \rReceiving objects:  68% (75/109)   \rReceiving objects:  69% (76/109)   \rReceiving objects:  70% (77/109)   \rReceiving objects:  71% (78/109)   \rReceiving objects:  72% (79/109)   \rReceiving objects:  73% (80/109)   \rReceiving objects:  74% (81/109)   \rReceiving objects:  75% (82/109)   \rReceiving objects:  76% (83/109)   \rReceiving objects:  77% (84/109)   \rReceiving objects:  78% (86/109)   \rReceiving objects:  79% (87/109)   \rReceiving objects:  80% (88/109)   \rReceiving objects:  81% (89/109)   \rReceiving objects:  82% (90/109)   \rReceiving objects:  83% (91/109)   \rReceiving objects:  84% (92/109)   \rReceiving objects:  85% (93/109)   \rReceiving objects:  86% (94/109)   \rReceiving objects:  87% (95/109)   \rReceiving objects:  88% (96/109)   \rReceiving objects:  89% (98/109)   \rReceiving objects:  90% (99/109)   \rReceiving objects:  91% (100/109)   \rReceiving objects:  92% (101/109)   \rReceiving objects:  93% (102/109)   \rReceiving objects:  94% (103/109)   \rReceiving objects:  95% (104/109)   \rReceiving objects:  96% (105/109)   \rReceiving objects:  97% (106/109)   \rReceiving objects:  98% (107/109)   \rReceiving objects:  99% (108/109)   \rReceiving objects: 100% (109/109)   \rReceiving objects: 100% (109/109), 154.25 KiB | 430.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/25)   \rResolving deltas:  16% (4/25)   \rResolving deltas:  20% (5/25)   \rResolving deltas:  24% (6/25)   \rResolving deltas:  36% (9/25)   \rResolving deltas:  44% (11/25)   \rResolving deltas:  48% (12/25)   \rResolving deltas:  52% (13/25)   \rResolving deltas:  56% (14/25)   \rResolving deltas:  60% (15/25)   \rResolving deltas:  64% (16/25)   \rResolving deltas:  72% (18/25)   \rResolving deltas:  80% (20/25)   \rResolving deltas:  84% (21/25)   \rResolving deltas:  88% (22/25)   \rResolving deltas:  92% (23/25)   \rResolving deltas:  96% (24/25)   \rResolving deltas: 100% (25/25)   \rResolving deltas: 100% (25/25), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PULx_0fmxbOh",
        "colab_type": "code",
        "outputId": "cec45f07-ec8f-4309-9da3-d0dbc5e6ef62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install ./tapas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Successfully uninstalled tensorflow-2.2.0\n",
            "Processing ./tapas\n",
            "Collecting bert-tensorflow==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hCollecting frozendict==1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Requirement already satisfied: scikit-learn~=0.22.1 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (1.0.3)\n",
            "Collecting tensorflow-gpu~=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 45kB/s \n",
            "\u001b[?25hCollecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses~=0.7 in /usr/local/lib/python3.6/dist-packages (from tapas==0.0.1.dev0) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1->tapas==0.0.1.dev0) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas==0.0.1.dev0) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0.0->tapas==0.0.1.dev0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas~=1.0.0->tapas==0.0.1.dev0) (2018.9)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.34.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.29.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.12.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0->tapas==0.0.1.dev0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.7.0->tapas==0.0.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (46.4.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu~=1.14.0->tapas==0.0.1.dev0) (3.1.0)\n",
            "Building wheels for collected packages: tapas, frozendict\n",
            "  Building wheel for tapas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tapas: filename=tapas-0.0.1.dev0-cp36-none-any.whl size=153403 sha256=6410033ac2b9fcfdcc9ffd0afd0e5806e6947e1c8ac61b21633388b7693de0a7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tsw4xzf3/wheels/2f/0b/d5/7e7fd15d1eb9839bd9768eaa6af2e0446329927b0f0c351387\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp36-none-any.whl size=3149 sha256=91438a92bcbecb4b4b8f5e91f3ee21e60176c29ec3e697e9ec6eb0155bc12de6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "Successfully built tapas frozendict\n",
            "Installing collected packages: bert-tensorflow, frozendict, tensorboard, tensorflow-estimator, tensorflow-gpu, tensorflow-probability, tapas\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow-probability 0.10.0\n",
            "    Uninstalling tensorflow-probability-0.10.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.10.0\n",
            "Successfully installed bert-tensorflow-1.0.1 frozendict-1.2 tapas-0.0.1.dev0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 tensorflow-probability-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7We9ofHuFMuk",
        "colab_type": "text"
      },
      "source": [
        "# Fetch models fom Google Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA1jUByqyUNB",
        "colab_type": "text"
      },
      "source": [
        "Next we can get pretrained checkpoint from Google Storage. For the sake of speed, this is base sized model trained on [SQA](https://www.microsoft.com/en-us/download/details.aspx?id=54253). Note that best results in the paper were obtained with with a large model, with 24 layers instead of 12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10C0Yz6gQyD",
        "colab_type": "code",
        "outputId": "fa7c96cc-985d-4899-b1f0-a0bc5cb96618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! gsutil cp gs://tapas_models/2020_04_21/tapas_sqa_base.zip . && unzip tapas_sqa_base.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tapas_models/2020_04_21/tapas_sqa_base.zip...\n",
            "| [1 files][  1.0 GiB/  1.0 GiB]   27.1 MiB/s                                   \n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n",
            "Archive:  tapas_sqa_base.zip\n",
            "   creating: tapas_sqa_base/\n",
            "  inflating: tapas_sqa_base/model.ckpt.data-00000-of-00001  \n",
            "  inflating: tapas_sqa_base/model.ckpt.index  \n",
            "  inflating: tapas_sqa_base/README.txt  \n",
            "  inflating: tapas_sqa_base/vocab.txt  \n",
            "  inflating: tapas_sqa_base/bert_config.json  \n",
            "  inflating: tapas_sqa_base/model.ckpt.meta  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3107bGlGm7d",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnUjDlLqDd3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ea9b3fb1-885e-4949-d103-1f2d3d0c7569"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import os \n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import IPython\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aml6oLFl1dSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tapas.utils import tf_example_utils\n",
        "from tapas.protos import interaction_pb2\n",
        "from tapas.utils import number_annotation_utils\n",
        "from tapas.scripts import prediction_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMUYT1bKMp9",
        "colab_type": "text"
      },
      "source": [
        "# Load checkpoint for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO0d_wFMy82O",
        "colab_type": "text"
      },
      "source": [
        "Here's the prediction code, which will create and `interaction_pb2.Interaction` protobuf object, which is the datastructure we use to store examples, and then call the prediction script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKfxspnVFPsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('results/sqa/tf_examples', exist_ok=True)\n",
        "os.makedirs('results/sqa/model', exist_ok=True)\n",
        "with open('results/sqa/model/checkpoint', 'w') as f:\n",
        "  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "  shutil.copyfile(f'tapas_sqa_base/model.ckpt{suffix}', f'results/sqa/model/model.ckpt-0{suffix}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RlvgDAmCNtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 512\n",
        "vocab_file = \"tapas_sqa_base/vocab.txt\"\n",
        "config = tf_example_utils.ClassifierConversionConfig(\n",
        "    vocab_file=vocab_file,\n",
        "    max_seq_length=max_seq_length,\n",
        "    max_column_id=max_seq_length,\n",
        "    max_row_id=max_seq_length,\n",
        "    strip_column_names=False,\n",
        "    add_aggregation_candidates=False,\n",
        ")\n",
        "converter = tf_example_utils.ToClassifierTensorflowExample(config)\n",
        "\n",
        "def convert_interactions_to_examples(tables_and_queries):\n",
        "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
        "  for idx, (table, queries) in enumerate(tables_and_queries):\n",
        "    interaction = interaction_pb2.Interaction()\n",
        "    for position, query in enumerate(queries):\n",
        "      question = interaction.questions.add()\n",
        "      question.original_text = query\n",
        "      question.id = f\"{idx}-0_{position}\"\n",
        "    for header in table[0]:\n",
        "      interaction.table.columns.add().text = header\n",
        "    for line in table[1:]:\n",
        "      row = interaction.table.rows.add()\n",
        "      for cell in line:\n",
        "        row.cells.add().text = cell\n",
        "    number_annotation_utils.add_numeric_values(interaction)\n",
        "    for i in range(len(interaction.questions)):\n",
        "      try:\n",
        "        yield converter.convert(interaction, i)\n",
        "      except ValueError as e:\n",
        "        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
        "        \n",
        "def write_tf_example(filename, examples):\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "def predict(table_data, queries):\n",
        "  table = [list(map(lambda s: s.strip(), row.split(\"|\"))) \n",
        "           for row in table_data.split(\"\\n\") if row.strip()]\n",
        "  examples = convert_interactions_to_examples([(table, queries)])\n",
        "  write_tf_example(\"results/sqa/tf_examples/test.tfrecord\", examples)\n",
        "  write_tf_example(\"results/sqa/tf_examples/random-split-1-dev.tfrecord\", [])\n",
        "  \n",
        "  ! python tapas/tapas/run_task_main.py \\\n",
        "    --task=\"SQA\" \\\n",
        "    --output_dir=\"results\" \\\n",
        "    --noloop_predict \\\n",
        "    --test_batch_size={len(queries)} \\\n",
        "    --tapas_verbosity=\"ERROR\" \\\n",
        "    --compression_type= \\\n",
        "    --init_checkpoint=\"tapas_sqa_base/model.ckpt\" \\\n",
        "    --bert_config_file=\"tapas_sqa_base/bert_config.json\" \\\n",
        "    --mode=\"predict\" 2> error\n",
        "\n",
        "\n",
        "  results_path = \"results/sqa/model/test_sequence.tsv\"\n",
        "  all_coordinates = []\n",
        "  df = pd.DataFrame(table[1:], columns=table[0])\n",
        "  display(IPython.display.HTML(df.to_html(index=False)))\n",
        "  print()\n",
        "  with open(results_path) as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "    for row in reader:\n",
        "      coordinates = prediction_utils.parse_coordinates(row[\"answer_coordinates\"])\n",
        "      all_coordinates.append(coordinates)\n",
        "      answers = ', '.join([table[row + 1][col] for row, col in coordinates])\n",
        "      position = int(row['position'])\n",
        "      print(\">\", queries[position])\n",
        "      print(answers)\n",
        "  return all_coordinates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqu-I-M9QaoA",
        "colab_type": "text"
      },
      "source": [
        "# Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K76IyDZU5eBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ba6a006e-fe85-4992-f3a2-51fe47fb6c5f"
      },
      "source": [
        "#Performs well on simple SELECT Queries not involving any aggregation operation\n",
        "res1 = predict(\"\"\"\n",
        "ID  | CustomerName         | Address               | PostalCode       |Age   | Country\n",
        "1   | Patrick              | Obere Str. 57         | 12209            | 23   | Germany  \n",
        "2   | Alfred               | Via dei Fiorentini 66 | 05021            | 50   | Italy      \n",
        "3   | Priyal               | Dwarka                | 110078           | 22   | India\n",
        "4   | Siddharth            | Dwarka                | 110078           | 22   | India  \n",
        "5   | Alex                 | California            | 90201            | 34   | Spain  \n",
        "\n",
        "\"\"\", [\"what were the customer names?\",\n",
        "      \"how many countries are present?\",\n",
        "      \"which customers have the same country?\",\n",
        "      \"what is the average age of customers?\",\n",
        "      \"which customer has the maximum age?\"])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_built_with_cuda: True\n",
            "is_gpu_available: True\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Training or predicting ...\n",
            "Evaluation finished after training step 0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ID</th>\n",
              "      <th>CustomerName</th>\n",
              "      <th>Address</th>\n",
              "      <th>PostalCode</th>\n",
              "      <th>Age</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Patrick</td>\n",
              "      <td>Obere Str. 57</td>\n",
              "      <td>12209</td>\n",
              "      <td>23</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Alfred</td>\n",
              "      <td>Via dei Fiorentini 66</td>\n",
              "      <td>05021</td>\n",
              "      <td>50</td>\n",
              "      <td>Italy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Priyal</td>\n",
              "      <td>Dwarka</td>\n",
              "      <td>110078</td>\n",
              "      <td>22</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Siddharth</td>\n",
              "      <td>Dwarka</td>\n",
              "      <td>110078</td>\n",
              "      <td>22</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>Alex</td>\n",
              "      <td>California</td>\n",
              "      <td>90201</td>\n",
              "      <td>34</td>\n",
              "      <td>Spain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> what were the customer names?\n",
            "Patrick, Siddharth, Priyal, Alex, Alfred\n",
            "> how many countries are present?\n",
            "Spain, Italy, Germany, India, India\n",
            "> which customers have the same country?\n",
            "Siddharth, Alex, Priyal\n",
            "> what is the average age of customers?\n",
            "34\n",
            "> which customer has the maximum age?\n",
            "Alex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI7jNMUD-bj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "7f2ccc0e-dde6-4c4f-b9f0-ba32695eb2e9"
      },
      "source": [
        "#Testing the model with more data\n",
        "res2 = predict(\"\"\"\n",
        "ProductID  |\tProductName                                 |\tSupplierID\t  |  CategoryID  |\tUnit                |\tPrice\n",
        "1\t         |  Chais\t                                      |  1\t          |  1\t         |  10 boxes x 20 bags\t|  18\n",
        "2\t         |  Chang\t                                      |  1\t          |  1           | \t24 - 12 oz bottles\t|  19\n",
        "3\t         |  Aniseed Syrup \t                            |  1\t          |  2\t         |  12 - 550 ml bottles\t|  10\n",
        "4\t         |  Chef Anton's Cajun Seasoning                |  2\t          |  2\t         |  48 - 6 oz jars\t    |  22\n",
        "5\t         |  Chef Anton's Gumbo Mix\t                    |  2\t          |  2\t         |  36 boxes\t          |  21.35\n",
        "6\t         |  Grandma's Boysenberry Spread                |\t 3\t          |  2\t         |  12 - 8 oz jars\t    |  25\n",
        "7\t         |  Uncle Bob's Organic Dried Pears\t            |  3\t          |  7\t         |  12 - 1 lb pkgs.\t    |  30\n",
        "8\t         |  Northwoods Cranberry Sauce\t                |  3\t          |  2\t         |  12 - 12 oz jars\t    |  40\n",
        "9\t         |  Mishi Kobe Niku\t                            |  4\t          |  6\t         |  18 - 500 g pkgs.\t  |  97\n",
        "10\t       |  Ikura\t                                      |  4\t          |  8\t         |  12 - 200 ml jars\t  |  31\n",
        "11\t       |  Queso Cabrales\t                            |  5\t          |  4\t         |  1 kg pkg.\t          |  21\n",
        "12\t       |  Queso Manchego La Pastora                   |\t 5\t          |  4\t         |  10 - 500 g pkgs.\t  |  38\n",
        "13\t       |  Konbu\t                                      |  6\t          |  8\t         |  2 kg box\t          |  6\n",
        "14\t       |  Tofu\t                                      |  6\t          |  7\t         |  40 - 100 g pkgs.\t  |  23.25\n",
        "15\t       |  Genen Shouyu\t                              |  6\t          |  2\t         |  24 - 250 ml bottles\t|  15.5\n",
        "16\t       |  Pavlova\t                                    |  7\t          |  3\t         |  32 - 500 g boxes\t  |  17.45\n",
        "17\t       |  Alice Mutton\t                              |  7\t          |  6\t         |  20 - 1 kg tins\t    |  39\n",
        "18\t       |  Carnarvon Tigers                            |  7\t          |  8\t         |  16 kg pkg.\t        |  62.5\n",
        "19\t       |  Teatime Chocolate Biscuits\t                |  8\t          |  3\t         |  10 boxes x 12 pieces|  9.2\n",
        "20\t       |  Sir Rodney's Marmalade\t                    |  8\t          |  3\t         |  30 gift boxes\t      |  81\n",
        "\n",
        "\"\"\", [\"what are the product names?\",\n",
        "      \"how many ProductIDs are present?\",\n",
        "      \"how many units are present for the product Chais?\",\n",
        "      \"what is the highest price?\",\n",
        "      \"what is the lowest price of all products?\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_built_with_cuda: True\n",
            "is_gpu_available: True\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Training or predicting ...\n",
            "Evaluation finished after training step 0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>ProductID</th>\n",
              "      <th>ProductName</th>\n",
              "      <th>SupplierID</th>\n",
              "      <th>CategoryID</th>\n",
              "      <th>Unit</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Chais</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10 boxes x 20 bags</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Chang</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24 - 12 oz bottles</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Aniseed Syrup</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12 - 550 ml bottles</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Chef Anton's Cajun Seasoning</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>48 - 6 oz jars</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>Chef Anton's Gumbo Mix</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>36 boxes</td>\n",
              "      <td>21.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>Grandma's Boysenberry Spread</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>12 - 8 oz jars</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>Uncle Bob's Organic Dried Pears</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12 - 1 lb pkgs.</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>Northwoods Cranberry Sauce</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>12 - 12 oz jars</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>Mishi Kobe Niku</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>18 - 500 g pkgs.</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>Ikura</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>12 - 200 ml jars</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>Queso Cabrales</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1 kg pkg.</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>Queso Manchego La Pastora</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>10 - 500 g pkgs.</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>Konbu</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>2 kg box</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>Tofu</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>40 - 100 g pkgs.</td>\n",
              "      <td>23.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>Genen Shouyu</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>24 - 250 ml bottles</td>\n",
              "      <td>15.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>Pavlova</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>32 - 500 g boxes</td>\n",
              "      <td>17.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>Alice Mutton</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>20 - 1 kg tins</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>Carnarvon Tigers</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>16 kg pkg.</td>\n",
              "      <td>62.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>Teatime Chocolate Biscuits</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>10 boxes x 12 pieces</td>\n",
              "      <td>9.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>Sir Rodney's Marmalade</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>30 gift boxes</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> what are the product names?\n",
            "Chais, Tofu, Konbu, Ikura, Northwoods Cranberry Sauce, Mishi Kobe Niku, Uncle Bob's Organic Dried Pears, Chef Anton's Cajun Seasoning, Carnarvon Tigers, Aniseed Syrup, Pavlova, Alice Mutton, Genen Shouyu, Queso Manchego La Pastora, Queso Cabrales, Grandma's Boysenberry Spread, Sir Rodney's Marmalade, Chef Anton's Gumbo Mix, Chang, Teatime Chocolate Biscuits\n",
            "> how many ProductIDs are present?\n",
            "19, 10, 1, 8, 13, 4, 18, 9, 16, 7, 12, 3, 17, 15, 6, 20, 11, 2, 14, 5\n",
            "> how many units are present for the product Chais?\n",
            "10 boxes x 20 bags\n",
            "> what is the highest price?\n",
            "18\n",
            "> what is the lowest price of all products?\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPAJpeRYQBC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}